{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init complete\n"
     ]
    }
   ],
   "source": [
    "# NOTE: For this to work the imagenet-vgg-verydeep-19.mat file must be in the folder with the notebook.\n",
    "# But it's large so I'm not checking it into git.\n",
    "# You will also want at least one of the corresponding checkpoints as well.\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import numpy as np, pdb, os\n",
    "import vgg\n",
    "import transform\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "from utils import save_img, get_img, exists, list_files\n",
    "from argparse import ArgumentParser\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import subprocess\n",
    "import numpy\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import moviepy.video.io.ffmpeg_writer as ffmpeg_writer\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = '/gpu:0'\n",
    "\n",
    "\n",
    "def ffwd_video(path_in, path_out, checkpoint_dir, device_t='/gpu:0', batch_size=4):\n",
    "    video_clip = VideoFileClip(path_in, audio=False)\n",
    "    video_writer = ffmpeg_writer.FFMPEG_VideoWriter(path_out, video_clip.size, video_clip.fps, codec=\"libx264\",\n",
    "                                                    preset=\"medium\", bitrate=\"2000k\",\n",
    "                                                    audiofile=path_in, threads=None,\n",
    "                                                    ffmpeg_params=None)\n",
    "\n",
    "    g = tf.Graph()\n",
    "    soft_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    soft_config.gpu_options.allow_growth = True\n",
    "    with g.as_default(), g.device(device_t), \\\n",
    "            tf.Session(config=soft_config) as sess:\n",
    "        batch_shape = (batch_size, video_clip.size[1], video_clip.size[0], 3)\n",
    "        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n",
    "                                         name='img_placeholder')\n",
    "\n",
    "        preds = transform.net(img_placeholder)\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.isdir(checkpoint_dir):\n",
    "            ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                raise Exception(\"No checkpoint found...\")\n",
    "        else:\n",
    "            saver.restore(sess, checkpoint_dir)\n",
    "\n",
    "        X = np.zeros(batch_shape, dtype=np.float32)\n",
    "\n",
    "        def style_and_write(count):\n",
    "            for i in range(count, batch_size):\n",
    "                X[i] = X[count - 1]  # Use last frame to fill X\n",
    "            _preds = sess.run(preds, feed_dict={img_placeholder: X})\n",
    "            for i in range(0, count):\n",
    "                video_writer.write_frame(np.clip(_preds[i], 0, 255).astype(np.uint8))\n",
    "\n",
    "        frame_count = 0  # The frame count that written to X\n",
    "        for frame in video_clip.iter_frames():\n",
    "            X[frame_count] = frame\n",
    "            frame_count += 1\n",
    "            if frame_count == batch_size:\n",
    "                style_and_write(frame_count)\n",
    "                frame_count = 0\n",
    "\n",
    "        if frame_count != 0:\n",
    "            style_and_write(frame_count)\n",
    "\n",
    "        video_writer.close()\n",
    "\n",
    "\n",
    "# get img_shape\n",
    "def ffwd(data_in, paths_out, checkpoint_dir, device_t='/gpu:0', batch_size=4):\n",
    "    assert len(paths_out) > 0\n",
    "    is_paths = type(data_in[0]) == str\n",
    "    if is_paths:\n",
    "        assert len(data_in) == len(paths_out)\n",
    "        img_shape = get_img(data_in[0]).shape\n",
    "    else:\n",
    "        assert data_in.size[0] == len(paths_out)\n",
    "        img_shape = X[0].shape\n",
    "\n",
    "    g = tf.Graph()\n",
    "    batch_size = min(len(paths_out), batch_size)\n",
    "    curr_num = 0\n",
    "    soft_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    soft_config.gpu_options.allow_growth = True\n",
    "    with g.as_default(), g.device(device_t), \\\n",
    "            tf.Session(config=soft_config) as sess:\n",
    "        batch_shape = (batch_size,) + img_shape\n",
    "        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n",
    "                                         name='img_placeholder')\n",
    "\n",
    "        preds = transform.net(img_placeholder)\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.isdir(checkpoint_dir):\n",
    "            ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                raise Exception(\"No checkpoint found...\")\n",
    "        else:\n",
    "            saver.restore(sess, checkpoint_dir)\n",
    "\n",
    "        num_iters = int(len(paths_out)/batch_size)\n",
    "        for i in range(num_iters):\n",
    "            pos = i * batch_size\n",
    "            curr_batch_out = paths_out[pos:pos+batch_size]\n",
    "            if is_paths:\n",
    "                curr_batch_in = data_in[pos:pos+batch_size]\n",
    "                X = np.zeros(batch_shape, dtype=np.float32)\n",
    "                for j, path_in in enumerate(curr_batch_in):\n",
    "                    img = get_img(path_in)\n",
    "                    assert img.shape == img_shape, \\\n",
    "                        'Images have different dimensions. ' +  \\\n",
    "                        'Resize images or use --allow-different-dimensions.'\n",
    "                    X[j] = img\n",
    "            else:\n",
    "                X = data_in[pos:pos+batch_size]\n",
    "\n",
    "            _preds = sess.run(preds, feed_dict={img_placeholder:X})\n",
    "            for j, path_out in enumerate(curr_batch_out):\n",
    "                save_img(path_out, _preds[j])\n",
    "                \n",
    "        remaining_in = data_in[num_iters*batch_size:]\n",
    "        remaining_out = paths_out[num_iters*batch_size:]\n",
    "    if len(remaining_in) > 0:\n",
    "        ffwd(remaining_in, remaining_out, checkpoint_dir, \n",
    "            device_t=device_t, batch_size=1)\n",
    "\n",
    "def ffwd_to_img(in_path, out_path, checkpoint_dir, device='/cpu:0'):\n",
    "    paths_in, paths_out = [in_path], [out_path]\n",
    "    ffwd(paths_in, paths_out, checkpoint_dir, batch_size=1, device_t=device)\n",
    "\n",
    "def ffwd_different_dimensions(in_path, out_path, checkpoint_dir, \n",
    "            device_t=DEVICE, batch_size=4):\n",
    "    in_path_of_shape = defaultdict(list)\n",
    "    out_path_of_shape = defaultdict(list)\n",
    "    for i in range(len(in_path)):\n",
    "        in_image = in_path[i]\n",
    "        out_image = out_path[i]\n",
    "        shape = \"%dx%dx%d\" % get_img(in_image).shape\n",
    "        in_path_of_shape[shape].append(in_image)\n",
    "        out_path_of_shape[shape].append(out_image)\n",
    "    for shape in in_path_of_shape:\n",
    "        print('Processing images of shape %s' % shape)\n",
    "        ffwd(in_path_of_shape[shape], out_path_of_shape[shape], \n",
    "            checkpoint_dir, device_t, batch_size)\n",
    "\n",
    "def build_parser():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--checkpoint', type=str,\n",
    "                        dest='checkpoint_dir',\n",
    "                        help='dir or .ckpt file to load checkpoint from',\n",
    "                        metavar='CHECKPOINT', required=True)\n",
    "\n",
    "    parser.add_argument('--in-path', type=str,\n",
    "                        dest='in_path',help='dir or file to transform',\n",
    "                        metavar='IN_PATH', required=True)\n",
    "\n",
    "    help_out = 'destination (dir or file) of transformed file or files'\n",
    "    parser.add_argument('--out-path', type=str,\n",
    "                        dest='out_path', help=help_out, metavar='OUT_PATH',\n",
    "                        required=True)\n",
    "\n",
    "    parser.add_argument('--device', type=str,\n",
    "                        dest='device',help='device to perform compute on',\n",
    "                        metavar='DEVICE', default=DEVICE)\n",
    "\n",
    "    parser.add_argument('--batch-size', type=int,\n",
    "                        dest='batch_size',help='batch size for feedforwarding',\n",
    "                        metavar='BATCH_SIZE', default=BATCH_SIZE)\n",
    "\n",
    "    parser.add_argument('--allow-different-dimensions', action='store_true',\n",
    "                        dest='allow_different_dimensions', \n",
    "                        help='allow different image dimensions')\n",
    "\n",
    "    return parser\n",
    "\n",
    "def check_opts(opts):\n",
    "    exists(opts.checkpoint_dir, 'Checkpoint not found!')\n",
    "    exists(opts.in_path, 'In path not found!')\n",
    "    if os.path.isdir(opts.out_path):\n",
    "        exists(opts.out_path, 'out dir not found!')\n",
    "        assert opts.batch_size > 0\n",
    "\n",
    "def main():\n",
    "    checkpoint_dir='../../fast-style-transfer/checkpoints/wave.ckpt'\n",
    "    in_path='in'\n",
    "    out_path='out'\n",
    "    if not os.path.isdir(in_path):\n",
    "        if os.path.exists(out_path) and os.path.isdir(out_path):\n",
    "            out_path = \\\n",
    "                    os.path.join(out_path,os.path.basename(in_path))\n",
    "\n",
    "        ffwd_to_img(in_path, out_path, checkpoint_dir,\n",
    "                    device=DEVICE)\n",
    "    else:\n",
    "        files = list_files(in_path)\n",
    "        full_in = [os.path.join(in_path,x) for x in files]\n",
    "        full_out = [os.path.join(out_path,x) for x in files]\n",
    "        allow_different_dimensions=True\n",
    "        if allow_different_dimensions:\n",
    "            ffwd_different_dimensions(full_in, full_out, checkpoint_dir, \n",
    "                    device_t=DEVICE, batch_size=BATCH_SIZE)\n",
    "        else :\n",
    "            ffwd(full_in, full_out, checkpoint_dir, device_t=device,\n",
    "                    batch_size=BATCH_SIZE)\n",
    "\n",
    "print('Init complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images of shape 488x338x3\n",
      "INFO:tensorflow:Restoring parameters from ../../fast-style-transfer/checkpoints/wave.ckpt\n",
      "total 88\n",
      "drwxrwx--x. 2 root aid_sdcard_rw  4096 Jul 14 23:55 .\n",
      "drwxrwx--x. 5 root aid_sdcard_rw  4096 Jul 14 23:55 ..\n",
      "-rw-rw----. 1 root aid_sdcard_rw 28854 Jul 14 23:45 fish.jpg\n",
      "-rw-rw----. 1 root aid_sdcard_rw 43002 Jul 14 23:55 monacat.jpg\n",
      "-rw-rw----. 1 root aid_sdcard_rw    36 Jul 14 23:22 readme.txt\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "!ls -al out\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img width='100' src='in/monacat.jpg'/> <img width='100' src='out/monacat.jpg'/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img width='100' src='in/monacat.jpg'/> <img width='100' src='out/monacat.jpg'/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
